{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 1: Global Configuration & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global configuration\n",
    "IMAGE_FOLDER = r\"C:\\Users\\samih\\Documents\\ShareX\\Screenshots\\For VS Vision\\New FOV 33 x 33 - Only Leaves 3D\"\n",
    "images_folder = IMAGE_FOLDER\n",
    "grid_size = 33\n",
    "TIME_STEP = 1  # TIME STEP BETWEEN IMAGES in seconds (for quantification)\n",
    "# image_step: process every Nth image (default = 1 processes every image)\n",
    "default_image_step = 3\n",
    "\n",
    "# Import dependencies\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.cm as cm\n",
    "from IPython.display import HTML, display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 2: RAW Image Loading and Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_images(images_folder, image_step=default_image_step):\n",
    "    \"\"\"\n",
    "    Load all RAW image files (PNG or JPG) from the folder sorted by modification time,\n",
    "    then subsample based on image_step.\n",
    "    \"\"\"\n",
    "    image_paths = sorted(glob.glob(os.path.join(images_folder, \"*.png\")), key=os.path.getmtime)\n",
    "    if not image_paths:\n",
    "        image_paths = sorted(glob.glob(os.path.join(images_folder, \"*.jpg\")), key=os.path.getmtime)\n",
    "    # Subsample the image paths: select index 0, image_step, 2*image_step, ...\n",
    "    image_paths = image_paths[::image_step]\n",
    "    \n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Could not load image {path}\")\n",
    "        else:\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            images.append(img_rgb)\n",
    "    if not images:\n",
    "        raise ValueError(\"No images were loaded. Please check your folder path and file types.\")\n",
    "    return images\n",
    "\n",
    "def animate_raw_images(images, image_step=default_image_step):\n",
    "    \"\"\"\n",
    "    Animate RAW images using Matplotlib.\n",
    "    The frame title is labeled as \"Time = {t} seconds\", where t = (frame index)*(image_step).\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    im_plot = ax.imshow(images[0])\n",
    "    title = ax.set_title(\"Time = 0 seconds\")\n",
    "    ax.axis('off')\n",
    "    \n",
    "    def update(frame):\n",
    "        im_plot.set_data(images[frame])\n",
    "        time_label = frame * image_step  # first image is 0 sec\n",
    "        title.set_text(f\"Time = {time_label} seconds\")\n",
    "        return [im_plot, title]\n",
    "    \n",
    "    anim = animation.FuncAnimation(fig, update, frames=len(images), interval=500, blit=False, repeat=True)\n",
    "    display(HTML(anim.to_jshtml()))\n",
    "    plt.show()\n",
    "\n",
    "# Example usage for RAW images:\n",
    "raw_images = load_raw_images(images_folder, image_step=default_image_step)\n",
    "animate_raw_images(raw_images, image_step=default_image_step)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 3: Classification Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_cell_color(avg_bgr):\n",
    "    \"\"\"\n",
    "    Classify a cell based on its average BGR color.\n",
    "    Returns:\n",
    "      'green' for leaves,\n",
    "      'orange' for fire,\n",
    "      'white' for burnt/empty.\n",
    "    \"\"\"\n",
    "    b, g, r = avg_bgr\n",
    "    color_bgr = np.uint8([[avg_bgr]])\n",
    "    color_hsv = cv2.cvtColor(color_bgr, cv2.COLOR_BGR2HSV)[0, 0]\n",
    "    h, s, v = color_hsv\n",
    "    if 30 <= h <= 90 and s > 50 and v > 50:\n",
    "        return 'green'\n",
    "    elif 0 <= h <= 40 and s > 60 and v > 60:\n",
    "        return 'orange'\n",
    "    else:\n",
    "        return 'white'\n",
    "\n",
    "def process_image_into_grid(img, grid_size=33):\n",
    "    \"\"\"\n",
    "    Splits an image into a grid_size x grid_size grid.\n",
    "    Outer border cells are set to 'black'; inner cells are classified.\n",
    "    Returns:\n",
    "      - A (grid_size x grid_size) NumPy array of labels.\n",
    "      - A color-coded classification image (RGB; one pixel per cell).\n",
    "    \"\"\"\n",
    "    height, width, _ = img.shape\n",
    "    cell_h = height // grid_size\n",
    "    cell_w = width // grid_size\n",
    "    labels = []\n",
    "    classified_img = np.zeros((grid_size, grid_size, 3), dtype=np.uint8)\n",
    "    for row in range(grid_size):\n",
    "        row_labels = []\n",
    "        for col in range(grid_size):\n",
    "            if row == 0 or row == grid_size - 1 or col == 0 or col == grid_size - 1:\n",
    "                label = 'black'\n",
    "            else:\n",
    "                y_start = row * cell_h\n",
    "                y_end   = (row + 1) * cell_h\n",
    "                x_start = col * cell_w\n",
    "                x_end   = (col + 1) * cell_w\n",
    "                cell = img[y_start:y_end, x_start:x_end]\n",
    "                avg_b = np.mean(cell[:, :, 0])\n",
    "                avg_g = np.mean(cell[:, :, 1])\n",
    "                avg_r = np.mean(cell[:, :, 2])\n",
    "                label = classify_cell_color((avg_b, avg_g, avg_r))\n",
    "            row_labels.append(label)\n",
    "            if label == 'black':\n",
    "                classified_img[row, col] = (0, 0, 0)\n",
    "            elif label == 'green':\n",
    "                classified_img[row, col] = (0, 255, 0)\n",
    "            elif label == 'orange':\n",
    "                classified_img[row, col] = (255, 165, 0)\n",
    "            else:\n",
    "                classified_img[row, col] = (255, 255, 255)\n",
    "        labels.append(row_labels)\n",
    "    return np.array(labels), classified_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 4: Classified Image Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classified_images(images_folder, grid_size, upscale_factor=10, image_step=default_image_step):\n",
    "    \"\"\"\n",
    "    Loads all classified images from the folder.\n",
    "    It uses process_image_into_grid() to discretize each image,\n",
    "    then upscales the classified image for better visualization.\n",
    "    Only every nth image is processed, where n is image_step.\n",
    "    Returns a list of upscaled classified images.\n",
    "    \"\"\"\n",
    "    # Get image paths sorted by modification time (PNG or JPG)\n",
    "    image_paths = sorted(glob.glob(os.path.join(images_folder, \"*.png\")), key=os.path.getmtime)\n",
    "    if not image_paths:\n",
    "        image_paths = sorted(glob.glob(os.path.join(images_folder, \"*.jpg\")), key=os.path.getmtime)\n",
    "    \n",
    "    # Subsample image paths\n",
    "    image_paths = image_paths[::image_step]\n",
    "    \n",
    "    classified_images = []\n",
    "    for path in image_paths:\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            continue\n",
    "        # Process the image into a grid of labels and a classified image\n",
    "        _, cls_img = process_image_into_grid(img, grid_size=grid_size)\n",
    "        # Upscale the classified image (e.g., each cell becomes upscale_factor x upscale_factor pixels)\n",
    "        upscaled = cv2.resize(cls_img,\n",
    "                              (grid_size * upscale_factor, grid_size * upscale_factor),\n",
    "                              interpolation=cv2.INTER_NEAREST)\n",
    "        classified_images.append(upscaled)\n",
    "    return classified_images\n",
    "\n",
    "def animate_classified_images(classified_images, image_step=default_image_step):\n",
    "    \"\"\"\n",
    "    Animate a list of upscaled classified images.\n",
    "    Each frame is labeled as \"Time = {t} seconds\", where t = (frame index)*image_step.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    im_plot = ax.imshow(classified_images[0])\n",
    "    title = ax.set_title(\"Time = 0 seconds\")\n",
    "    ax.axis('off')\n",
    "    \n",
    "    def update(frame):\n",
    "        im_plot.set_data(classified_images[frame])\n",
    "        time_label = frame * image_step  # first image is time 0\n",
    "        title.set_text(f\"Time = {time_label} seconds\")\n",
    "        return [im_plot, title]\n",
    "    \n",
    "    anim = animation.FuncAnimation(fig, update, frames=len(classified_images),\n",
    "                                   interval=500, blit=False, repeat=True)\n",
    "    display(HTML(anim.to_jshtml()))\n",
    "    plt.show()\n",
    "\n",
    "# --- Example usage for animating classified images ---\n",
    "classified_images = get_classified_images(images_folder, grid_size=grid_size,\n",
    "                                            upscale_factor=10, image_step=default_image_step)\n",
    "animate_classified_images(classified_images, image_step=default_image_step)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 5: Side‑by‑Side-by-Side Comparison (Original vs. Classified vs. Isochrone Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_isochrone_contours(labels_grid, upscale_factor=10):\n",
    "    \"\"\"\n",
    "    Create a binary mask from the classification grid for cells labeled as \n",
    "    'orange' or 'white', upscale it, and find contours.\n",
    "    \"\"\"\n",
    "    grid_size_local = labels_grid.shape[0]\n",
    "    mask = np.zeros((grid_size_local, grid_size_local), dtype=np.uint8)\n",
    "    for r in range(grid_size_local):\n",
    "        for c in range(grid_size_local):\n",
    "            if labels_grid[r, c] in ('orange', 'white'):\n",
    "                mask[r, c] = 255\n",
    "    upscaled_size = (grid_size_local * upscale_factor, grid_size_local * upscale_factor)\n",
    "    mask_upscaled = cv2.resize(mask, upscaled_size, interpolation=cv2.INTER_NEAREST)\n",
    "    contours, _ = cv2.findContours(mask_upscaled, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours\n",
    "\n",
    "def draw_isochrone_only(labels_grid, upscale_factor=10):\n",
    "    \"\"\"\n",
    "    Create a blank white canvas and draw the isochrone contour (outline) \n",
    "    from the classification grid using thin red lines.\n",
    "    \"\"\"\n",
    "    grid_size_local = labels_grid.shape[0]\n",
    "    upscaled_size = (grid_size_local * upscale_factor, grid_size_local * upscale_factor)\n",
    "    contours = get_isochrone_contours(labels_grid, upscale_factor=upscale_factor)\n",
    "    outline_img = 255 * np.ones((upscaled_size[1], upscaled_size[0], 3), dtype=np.uint8)\n",
    "    if contours:\n",
    "        cv2.drawContours(outline_img, contours, -1, (255, 0, 0), 1)\n",
    "    return outline_img\n",
    "\n",
    "def show_three_panel_comparison(images_folder, grid_size=33, upscale_factor=10, image_step=default_image_step):\n",
    "    \"\"\"\n",
    "    For each (or every nth) image in the folder, display a single figure with\n",
    "    three panels:\n",
    "      - Left: Original image (converted to RGB)\n",
    "      - Middle: Classified image (discretised & upscaled)\n",
    "      - Right: Isochrone-only image (firefront outline, upscaled)\n",
    "      \n",
    "    Time is labeled as \"Time = t sec\", where t = (image index * image_step),\n",
    "    with the first image counted as time = 0 sec.\n",
    "    \"\"\"\n",
    "    # Get image paths sorted by modification time and subsample using image_step\n",
    "    image_paths = sorted(glob.glob(os.path.join(images_folder, \"*.png\")), key=os.path.getmtime)\n",
    "    if not image_paths:\n",
    "        image_paths = sorted(glob.glob(os.path.join(images_folder, \"*.jpg\")), key=os.path.getmtime)\n",
    "    image_paths = image_paths[::image_step]\n",
    "    \n",
    "    for idx, path in enumerate(image_paths):\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Could not load image {path}\")\n",
    "            continue\n",
    "\n",
    "        # Convert original image to RGB.\n",
    "        orig_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Process image to obtain grid classification.\n",
    "        labels_grid, classified_img = process_image_into_grid(img, grid_size=grid_size)\n",
    "        # Upscale the classified image for better visualization.\n",
    "        upscaled_classified = cv2.resize(classified_img,\n",
    "                                         (classified_img.shape[1] * upscale_factor,\n",
    "                                          classified_img.shape[0] * upscale_factor),\n",
    "                                         interpolation=cv2.INTER_NEAREST)\n",
    "        # Generate the isochrone-only image.\n",
    "        isochrone_img = draw_isochrone_only(labels_grid, upscale_factor=upscale_factor)\n",
    "\n",
    "        # Calculate the time label: first image is 0 sec.\n",
    "        time_label = idx * image_step\n",
    "\n",
    "        # Create a single figure with three subplots (side-by-side)\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "        \n",
    "        axes[0].imshow(orig_rgb)\n",
    "        axes[0].set_title(f\"Original (Time = {time_label} sec)\")\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        axes[1].imshow(upscaled_classified)\n",
    "        axes[1].set_title(f\"Classified (Time = {time_label} sec)\")\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        axes[2].imshow(cv2.cvtColor(isochrone_img, cv2.COLOR_BGR2RGB))\n",
    "        axes[2].set_title(f\"Isochrone (Time = {time_label} sec)\")\n",
    "        axes[2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Example usage: process and display three-panel comparison using the default_image_step\n",
    "show_three_panel_comparison(images_folder, grid_size=grid_size, upscale_factor=10, image_step=default_image_step)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 6: Overlay of Isochrones (Colour Gradient Option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_all_isochrones_color_gradient(images_folder, grid_size=33, upscale_factor=10, line_thickness=1, image_step=default_image_step):\n",
    "    \"\"\"\n",
    "    For all (or every nth) image in the folder, compute the firefront contours\n",
    "    and overlay them on a single white canvas using a color gradient.\n",
    "    Each processed image is labeled as \"Time = t sec\" where t = index * image_step.\n",
    "    A colorbar is added as a key to map colors to time.\n",
    "    \"\"\"\n",
    "    # Get and subsample image paths\n",
    "    image_paths = sorted(glob.glob(os.path.join(images_folder, \"*.png\")), key=os.path.getmtime)\n",
    "    if not image_paths:\n",
    "        image_paths = sorted(glob.glob(os.path.join(images_folder, \"*.jpg\")), key=os.path.getmtime)\n",
    "    if not image_paths:\n",
    "        raise ValueError(\"No images found in the specified folder.\")\n",
    "    image_paths = image_paths[::image_step]\n",
    "    \n",
    "    # Get colormap from matplotlib\n",
    "    cmap = cm.get_cmap('jet', len(image_paths))\n",
    "    upscaled_size = (grid_size * upscale_factor, grid_size * upscale_factor)\n",
    "    overlay_img = 255 * np.ones((upscaled_size[1], upscaled_size[0], 3), dtype=np.uint8)\n",
    "    \n",
    "    for i, path in enumerate(image_paths):\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Could not load image {path}\")\n",
    "            continue\n",
    "        labels_grid, _ = process_image_into_grid(img, grid_size=grid_size)\n",
    "        contours = get_isochrone_contours(labels_grid, upscale_factor=upscale_factor)\n",
    "        # Get the distinct color for this time step from the colormap\n",
    "        color_rgba = cmap(i)\n",
    "        # Convert RGBA (0-1) to BGR (0-255) since OpenCV uses BGR order\n",
    "        color_bgr = (int(color_rgba[2]*255), int(color_rgba[1]*255), int(color_rgba[0]*255))\n",
    "        if contours:\n",
    "            cv2.drawContours(overlay_img, contours, -1, color_bgr, line_thickness)\n",
    "\n",
    "    # Plot the final overlay image with a colorbar key that maps time.\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    # Convert BGR overlay to RGB for correct display in matplotlib.\n",
    "    ax.imshow(cv2.cvtColor(overlay_img, cv2.COLOR_BGR2RGB))\n",
    "    ax.set_title(\"Overlay of Isochrones (Color Gradient)\")\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Create a ScalarMappable for the colorbar.\n",
    "    # We assume the time values run from 0 to (n-1)*image_step seconds.\n",
    "    norm = plt.Normalize(vmin=0, vmax=(len(image_paths)-1)*image_step)\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    cbar = fig.colorbar(sm, ax=ax, fraction=0.046, pad=0.04, ticks=np.linspace(0, (len(image_paths)-1)*image_step, num=len(image_paths)))\n",
    "    cbar.set_label(\"Time (seconds)\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Run overlay of isochrones with color gradient and key\n",
    "overlay_all_isochrones_color_gradient(images_folder, grid_size=grid_size, upscale_factor=10, line_thickness=1, image_step=default_image_step)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 7: Fire Spread Quantification and Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_process_image_into_grid(img, grid_size=grid_size):\n",
    "    \"\"\"\n",
    "    Splits the input image into a grid_size x grid_size grid.\n",
    "    Outer border cells are set to 'black'. Inner cells are classified.\n",
    "    Returns a (grid_size x grid_size) NumPy array of labels.\n",
    "    \"\"\"\n",
    "    height, width, _ = img.shape\n",
    "    cell_h = height // grid_size\n",
    "    cell_w = width // grid_size\n",
    "    labels = []\n",
    "    for row in range(grid_size):\n",
    "        row_labels = []\n",
    "        for col in range(grid_size):\n",
    "            if row == 0 or row == grid_size - 1 or col == 0 or col == grid_size - 1:\n",
    "                row_labels.append('black') \n",
    "            else:\n",
    "                y_start = row * cell_h\n",
    "                y_end   = (row + 1) * cell_h\n",
    "                x_start = col * cell_w\n",
    "                x_end   = (col + 1) * cell_w\n",
    "                cell = img[y_start:y_end, x_start:x_end]\n",
    "                avg_b = np.mean(cell[:, :, 0])\n",
    "                avg_g = np.mean(cell[:, :, 1])\n",
    "                avg_r = np.mean(cell[:, :, 2])\n",
    "                row_labels.append(classify_cell_color((avg_b, avg_g, avg_r)))\n",
    "        labels.append(row_labels)\n",
    "    return np.array(labels)\n",
    "\n",
    "# Main code to iterate through images, count areas, and plot results.\n",
    "# Assumes a 1-second time step between images.\n",
    "# Get all image file paths (using images_folder defined earlier)\n",
    "image_paths = sorted(glob.glob(os.path.join(images_folder, '*.png')), key=os.path.getmtime)\n",
    "if not image_paths:\n",
    "    image_paths = sorted(glob.glob(os.path.join(images_folder, '*.jpg')), key=os.path.getmtime)\n",
    "if not image_paths:\n",
    "    raise ValueError(\"No images found in the specified folder.\")\n",
    "\n",
    "# Lists to store the area (number of cells) per image\n",
    "fire_reached_area = []  # counts cells that are either 'orange' or 'white'\n",
    "fire_area = []          # counts cells that are 'orange'\n",
    "\n",
    "for path in image_paths:\n",
    "    img = cv2.imread(path)\n",
    "    if img is None:\n",
    "        print(f\"Warning: Could not load image {path}\")\n",
    "        continue\n",
    "    grid = graph_process_image_into_grid(img, grid_size=grid_size)\n",
    "    # Count cells that are either 'orange' or 'white'\n",
    "    reached_count = np.sum((grid == 'orange') | (grid == 'white'))\n",
    "    # Count cells that are just 'orange'\n",
    "    fire_count = np.sum(grid == 'orange')\n",
    "    fire_reached_area.append(reached_count)\n",
    "    fire_area.append(fire_count)\n",
    "\n",
    "# Generate time points (in seconds)\n",
    "time_points = np.arange(len(fire_reached_area))  # since TIME_STEP is 1, time equals image index\n",
    "\n",
    "# Print the values that are being plotted:\n",
    "print(\"Time (seconds):\", time_points)\n",
    "print(\"Fire Reached Area (cells, orange+white):\", fire_reached_area)\n",
    "print(\"Fire Area (cells, orange only):\", fire_area)\n",
    "\n",
    "# Plot the total area over time\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(time_points, fire_reached_area, marker='o', label='Fire Reached Area (orange+white)')\n",
    "plt.plot(time_points, fire_area, marker='s', label='Fire Area (orange)')\n",
    "plt.xlabel(\"Time (seconds)\")\n",
    "plt.ylabel(\"Number of Cells\")\n",
    "plt.title(\"Fire Spread Area Over Time\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compute the differences between consecutive images (new cells per second)\n",
    "fire_reached_diff = np.diff(fire_reached_area)\n",
    "fire_area_diff = np.diff(fire_area)\n",
    "\n",
    "# Print the differences (rate of spread)\n",
    "print(\"New Fire Reached Area per second (cells):\", fire_reached_diff)\n",
    "print(\"New Fire Area per second (cells):\", fire_area_diff)\n",
    "\n",
    "# Plot the rate of spread (area increase per second)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(time_points[1:], fire_reached_diff, marker='o', label='New Fire Reached Area per Second')\n",
    "plt.plot(time_points[1:], fire_area_diff, marker='s', label='New Fire Area per Second')\n",
    "plt.xlabel(\"Time (seconds)\")\n",
    "plt.ylabel(\"New Cells per Second\")\n",
    "plt.title(\"Fire Spread Rate (Area Increase per Second)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
